{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pathlib\n",
    "from random import shuffle, seed\n",
    "import numpy as np\n",
    "import re\n",
    "from subprocess import call\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_spaces = '''\n",
    "    <style>html *\n",
    "        {font-size: 16px !important;\n",
    "            line-height: 2.625 !important;\n",
    "            color: #000000 !important;\n",
    "            font-family: Nunito, sans-serif !important;}\n",
    "    </style>\n",
    "'''\n",
    "hor_line_general ='''\n",
    "<style>\n",
    "    hr {\n",
    "        display: block;\n",
    "        margin-top: 0em;\n",
    "        margin-bottom: 1.5em;\n",
    "        margin-left: auto;\n",
    "        margin-right: auto;\n",
    "        border-style: inset;\n",
    "        border-width: 1px;\n",
    "        width:100%\n",
    "    }\n",
    "    </style>\n",
    "    '''\n",
    "for_language = vertical_spaces + '<head><meta charset=\"utf-8\"><title>Tasks: </title></head>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Source_Scrapper:\n",
    "\n",
    "    def __init__(self, url, task_num):\n",
    "        self.url = url\n",
    "        self.task_num = task_num\n",
    "        self.first_step()\n",
    "\n",
    "    def first_step(self):\n",
    "        response = requests.get(self.url)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        result_html = soup.prettify()\n",
    "        with open('page_source.txt', 'w') as f:\n",
    "            f.write(result_html)\n",
    "\n",
    "        self.tasks = soup.find_all('replace_tag', {'class': 'replace_class_name'})\n",
    "        self.answers = soup.find_all('replace_tag', {'class': 'replace_class_name'})\n",
    "\n",
    "\n",
    "    def answers_extractor(self, answer):\n",
    "        answer = str(answer)\n",
    "        answer = answer.replace(\"replace_tag\", 'S')\n",
    "        answer = answer.replace(\") );\", \"E\")\n",
    "        id = re.findall('\"\\d+\"', answer)\n",
    "        ans = re.findall(\"S'([^']*?)'E\", answer)\n",
    "        return [id, ans]\n",
    "    \n",
    "    def task_converter_teacher(self):\n",
    "        assert len(self.tasks) == len(self.answers)\n",
    "\n",
    "        tasks_final = []\n",
    "        for idx, task in enumerate(self.tasks):\n",
    "            task_answer = self.answers_extractor(self.answers[idx])\n",
    "            task = str(task)\n",
    "            task = task.replace(\n",
    "                \"replace_tag\",\n",
    "                f\"Задание ({str(task_answer[0][0])[1:-1]})\" + '\\n',\n",
    "            )\n",
    "            task = task.replace(\"') );\", 'END')\n",
    "            idx_end = task.find(\"END\")\n",
    "            idx_start = task.find(\"Задание\")\n",
    "            soup = BeautifulSoup(task[idx_start + 7:idx_end], 'html.parser')\n",
    "            pretty_task = soup.prettify()\n",
    "            tasks_final.append(\n",
    "                f'<br>{str(pretty_task)}<br>Answer: <br>{str(task_answer[1][0])}<hr>'\n",
    "            )\n",
    "        return tasks_final\n",
    "\n",
    "    def task_converter_student(self):\n",
    "        assert len(self.tasks) == len(self.answers)\n",
    "\n",
    "        tasks_final = []\n",
    "        for task in self.tasks:\n",
    "            task = str(task)\n",
    "            task = task.replace(\"replace_phrase\", 'Задание ')\n",
    "            task = task.replace(\"') );\", 'END')\n",
    "            idx_end = task.find(\"END\")\n",
    "            idx_start = task.find(\"Задание\")\n",
    "            soup = BeautifulSoup(task[idx_start + 7:idx_end], 'html.parser')\n",
    "            pretty_task = soup.prettify()\n",
    "            tasks_final.append(f'<br>{str(pretty_task)}<br><hr>')\n",
    "        return tasks_final\n",
    "\n",
    "\n",
    "    def write_to_file(self, student=True):\n",
    "        if student:\n",
    "            name = 'tutor_streamlit/streamlit_app/files/tasks/'\n",
    "            tasks_final = self.task_converter_student()\n",
    "        else:\n",
    "            name = 'files/answers/'\n",
    "            tasks_final = self.task_converter_teacher()\n",
    "        seed(42)\n",
    "        shuffle(tasks_final)\n",
    "        for idx, elem in enumerate(tasks_final):\n",
    "            mode = 'w' if idx == 0 else 'a'\n",
    "            with open(f'{name}task_{str(self.task_num)}.html', mode) as f:\n",
    "                if idx == 0:\n",
    "                    f.write(f'{for_language}Задание ' + f\"{idx + 1}. \" + elem)\n",
    "                else:\n",
    "                    f.write(f\"Задание {idx + 1}. {elem}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {\n",
    "    2: 'link_2',\n",
    "    3: 'link_3',\n",
    "    5: 'link_5',\n",
    "    6: 'link_6',\n",
    "    7: 'link_7',\n",
    "    8: 'link_8',\n",
    "    9: 'link_9',\n",
    "    11: 'link_11',\n",
    "    12: 'link_12',\n",
    "    13: 'link_13',\n",
    "    14: 'link_14',\n",
    "    15: 'link_15',\n",
    "    16: 'link_16',\n",
    "    17: 'link_17',\n",
    "    18: 'link_18',\n",
    "    19: 'link_19',\n",
    "    22: 'link_22',\n",
    "    23: 'link_23',\n",
    "    24: 'link_24',\n",
    "    25: 'link_25',\n",
    "    26: 'link_26',\n",
    "    27: 'link_27'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 22\n",
    "obj = Source_Scrapper(urls[num], num)\n",
    "obj.write_to_file(student=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
