{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Emojis in Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to build a predictive model of emoji in a given piece of text. Our suggestion is to use standard vectorization methods and machine learning classifiers (of your choice). Prepare a script for conducting the experiment, an instruction to reproduce your experiment results, and a report that includes the following:\n",
    "\n",
    "- Experiment results, including the standard metrics e.g. precisions, accuracies, f-measures, and confusion matrices (if applicable).\n",
    "\n",
    "- Your findings and observations are based on the experiments, including limitations and assumptions.\n",
    "\n",
    "- How you choose the vectorization method and algorithms.\n",
    "\n",
    "- What the experiments may be useful for and how we may improve their utility of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Included in this repository are two files:\n",
    "\n",
    "- *tweets.txt*, where each line includes the text of a tweet that included emoji (but the emoji has been removed);\n",
    "\n",
    "- *emoji.txt*, where each line includes the name of the emoji for the corresponding text in tweets.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TextVectorization, Embedding, Input, LSTM, Dense, Permute, Multiply, Lambda, Concatenate, Embedding, RepeatVector\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aws.aws_funcs import upload_to_s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(history, metrics='accuracy'):\n",
    "  \"\"\"\n",
    "  Plots training and validation loss curves, as well as accuracy (or other specified metric) curves for a model's training history.\n",
    "\n",
    "  This function takes the history object returned by a model's fit method in Keras/TensorFlow and plots both the training and \n",
    "  validation loss over epochs, as well as the training and validation accuracy (or another specified metric). This is useful \n",
    "  for visualizing the model's learning process and identifying issues like overfitting or underfitting.\n",
    "\n",
    "  Parameters:\n",
    "  - history: A Keras History object. This object is returned by the fit method of models in Keras and contains the loss and \n",
    "    metric values from training.\n",
    "  - metrics (str, optional): The name of the metric to plot alongside loss. Defaults to 'accuracy'.\n",
    "  \"\"\"\n",
    "\n",
    "  # sourcery skip: extract-duplicate-method\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  accuracy = history.history[metrics]\n",
    "  val_accuracy = history.history[f'val_{metrics}']\n",
    "\n",
    "  epochs = range(1, 1 + len(history.history['loss']))\n",
    "\n",
    "  fig, ax = plt.subplots(1, 2, figsize=(15, 4), dpi=200)\n",
    "\n",
    "  ax[0].plot(epochs, loss, label='training_loss')\n",
    "  ax[0].plot(epochs, val_loss, label='val_loss')\n",
    "  ax[0].set_title('loss')\n",
    "  ax[0].set_xlabel('epochs')\n",
    "  ax[0].legend()\n",
    "\n",
    "  ax[1].plot(epochs, accuracy, label=f'training_{metrics}')\n",
    "  ax[1].plot(epochs, val_accuracy, label=f'val_{metrics}')\n",
    "  ax[1].set_title(metrics)\n",
    "  ax[1].set_xlabel('epochs')\n",
    "  ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet_text(tweet_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocesses a tweet's text for NLP tasks by cleaning and normalizing the text.\n",
    "\n",
    "    This function applies a series of preprocessing steps to clean and normalize tweet text, making it more suitable for \n",
    "    natural language processing (NLP) tasks. The steps include stripping non-alphanumeric characters, reducing multiple \n",
    "    whitespaces to a single whitespace, removing punctuation, stripping numeric characters, stemming the text to reduce \n",
    "    words to their root form, and removing stopwords to eliminate common but uninformative words.\n",
    "\n",
    "    Parameters:\n",
    "    - tweet_text (str): The text of the tweet to be preprocessed.\n",
    "\n",
    "    Returns:\n",
    "    - str: The preprocessed and normalized tweet text.\n",
    "    \"\"\"\n",
    "\n",
    "    preprocessed_text = preprocessing.strip_non_alphanum(s=tweet_text)\n",
    "    preprocessed_text = preprocessing.strip_multiple_whitespaces(s=preprocessed_text)\n",
    "    preprocessed_text = preprocessing.strip_punctuation(s=preprocessed_text)\n",
    "    preprocessed_text = preprocessing.strip_numeric(s=preprocessed_text)\n",
    "\n",
    "    preprocessed_text = preprocessing.stem_text(text=preprocessed_text)\n",
    "    preprocessed_text = preprocessing.remove_stopwords(s=preprocessed_text)\n",
    "\n",
    "    return preprocessed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(features, labels, BATCH_SIZE=32):\n",
    "    \"\"\"\n",
    "    Converts features and labels into a TensorFlow dataset with batching and prefetching.\n",
    "\n",
    "    This function takes features and labels, converts them into TensorFlow datasets, and then combines them into a single dataset. \n",
    "    The combined dataset is shuffled, batched, and prefetched for optimal training performance. This is particularly useful for \n",
    "    preparing data for model training in TensorFlow, allowing for efficient data loading and processing.\n",
    "\n",
    "    Parameters:\n",
    "    - features (array-like): Input features for the model. Can be a list, NumPy array, or similar structures.\n",
    "    - labels (array-like): Corresponding labels for the input features.\n",
    "    - BATCH_SIZE (int, optional): The size of the batches of data. Defaults to 32.\n",
    "\n",
    "    Returns:\n",
    "    - dataset (tf.data.Dataset): A TensorFlow Dataset object ready for model training, including features and labels, shuffled \n",
    "    and batched.\n",
    "\n",
    "    Note: Requires TensorFlow to be imported as tf. 'tf.data.experimental.AUTOTUNE' is used to allow TensorFlow to dynamically \n",
    "    adjust the number of elements to prefetch based on the system's current state, improving runtime efficiency.\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset_features = tf.data.Dataset.from_tensor_slices(features)\n",
    "    dataset_labels = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    dataset = tf.data.Dataset.zip((dataset_features, dataset_labels))\n",
    "    dataset = dataset.shuffle(buffer_size=len(features)).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "  Args:\n",
    "  ----\n",
    "  y_true = true labels in the form of a 1D array\n",
    "  y_pred = predicted label in the form of a 1D array\n",
    "\n",
    "  Returns a dictionary of accuracy, precision, recall and f1-score between y_true and y_pred.\n",
    "  \"\"\"\n",
    "\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100 # get accuracy score in percentage value\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  return {\n",
    "      \"accuracy\": model_accuracy,\n",
    "      \"precision\": model_precision,\n",
    "      \"recall\": model_recall,\n",
    "      \"f1\": model_f1,\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_local_plots = 'path/to/plots/'\n",
    "def upload_to_aws_png(file_name):\n",
    "    upload_to_s3(f'{path_to_local_plots}{file_name}.png', f'path/to/plots/{file_name}.png')\n",
    "\n",
    "def upload_plot(plot_name):\n",
    "    plt.savefig(f'{path_to_local_plots}{plot_name}.png', dpi=300)\n",
    "    upload_to_aws_png(plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_local_csv = 'path/to/csv/'\n",
    "def upload_to_aws_csv(file_name):\n",
    "    upload_to_s3(f'{path_to_local_csv}{file_name}.csv', f'path/to/csv/{file_name}.csv')\n",
    "\n",
    "def upload_csv(df, csv_name):\n",
    "    df.to_csv(f'{path_to_local_csv}{csv_name}.csv', index=False)\n",
    "    upload_to_aws_csv(csv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data and Become One with It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_emoji = pathlib.Path('data/emoji.txt')\n",
    "path_tweets = pathlib.Path('data/tweets.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_emoji.__str__(), 'r', encoding='utf-8') as file:\n",
    "    lines = [elem.replace('\\n', '') for elem in file.readlines()]\n",
    "\n",
    "emoji_df = pd.DataFrame(lines, columns=['Tweets'])\n",
    "emoji_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(emoji_df['Tweets'], 'raw_emoji')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(emoji_df.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5), dpi=350)\n",
    "sns.countplot(data=emoji_df, y='Tweets');\n",
    "\n",
    "upload_plot('1_categories_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sourcery skip: dict-comprehension\n",
    "emoji_df.value_counts().max() / emoji_df.value_counts().min()\n",
    "ratio_max_others = {}\n",
    "for idx in emoji_df.value_counts().index:\n",
    "    ratio_max_others[f'Sob to {idx[0]}'] = (emoji_df.value_counts().loc[[\"sob\"]] / emoji_df.value_counts().loc[idx]).to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5), dpi=350)\n",
    "plt.xticks(rotation=45)\n",
    "plt.bar(ratio_max_others.keys(), ratio_max_others.values());\n",
    "upload_plot('2_unbalanced_check')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the data is a little unbalanced with maximum ration 5. We'll see later if it affects the predictions and probably will try to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_tweets.__str__(), 'r', encoding='utf-8') as file:\n",
    "    lines = [elem.replace('\\n', '') for elem in file.readlines()]\n",
    "\n",
    "tweets_df = pd.DataFrame(lines, columns=['Tweets'])\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(tweets_df, 'raw_tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5), dpi=150)\n",
    "plt.hist(tweets_df['Tweets'].apply(lambda x: len(x)), bins= 50);\n",
    "plt.xlabel('Tweet Length')\n",
    "plt.ylabel('Count')\n",
    "upload_plot('Tweets_Length_Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['tweets_preprocessed'] = tweets_df['Tweets'].apply(preprocess_tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(tweets_df, 'preprocessed_tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5), dpi=350)\n",
    "sns.histplot(data=tweets_df, x=tweets_df['tweets_preprocessed'].apply(len), kde=True)\n",
    "plt.xlabel('Length of Tweet in Symbols', labelpad=10)\n",
    "plt.title('Distribution of Length of Tweets in Symbols', pad=15);\n",
    "upload_plot('Tweet_Length_Symbols_Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5), dpi=350)\n",
    "sns.histplot(data=tweets_df, x=tweets_df['tweets_preprocessed'].apply(lambda x: x.split(' ')).apply(len))\n",
    "plt.xlabel('Length of Tweet in Words', labelpad=10)\n",
    "plt.title('Distribution of Length of Tweets in Words', pad=15);\n",
    "upload_plot('Tweet_Length_Words_Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "emoji_df['encoded'] = encoder.fit_transform(emoji_df[['Tweets']])\n",
    "emoji_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = dict(zip(encoder.categories_[0], iter(range(10))))\n",
    "id2label = dict(zip(iter(range(10)), encoder.categories_[0]))\n",
    "pd.Series(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(pd.Series(id2label), 'encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_final = tweets_df.drop('Tweets', axis=1)\n",
    "df = pd.merge(emoji_df, tweets_df_final, left_index=True, right_index=True).rename(columns={'encoded': 'emoji', 'tweets_preprocessed': 'tweets'}).drop('Tweets', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(\n",
    "    df['tweets'],\n",
    "    df['emoji'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(df.head(), 'head_final_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Text into Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=15_000,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    ngrams=None,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=30,\n",
    "    pad_to_max_tokens=True\n",
    ")\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how does it work\n",
    "sample_sentence = \"There's a flood in my street\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_10_words = words_in_vocab[:10]\n",
    "bottom_10_words = words_in_vocab[-10:]\n",
    "print(f'Most common words in vocab: {top_10_words}')\n",
    "print(f'Least common words in vocab: {bottom_10_words}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Embedding using an Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = layers.Embedding(\n",
    "    input_dim=15_000,\n",
    "    output_dim=128,\n",
    "    embeddings_initializer='uniform',\n",
    "    input_length=30\n",
    ")\n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_score = model_0.score(test_sentences, test_labels)\n",
    "f'Baseline Model achieves an accuracy of: {baseline_score * 100:.2f}%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing For Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences_vectorized = text_vectorizer(train_sentences)\n",
    "test_sentences_vectorized = text_vectorizer(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = to_dataset(train_sentences_vectorized, train_labels)\n",
    "dataset_test = to_dataset(test_sentences_vectorized, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(30,), dtype=\"int32\")\n",
    "x = embedding(inputs)\n",
    "x = layers.LSTM(64, activation=\"tanh\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_LSTM\")\n",
    "\n",
    "model_1.compile(loss=\"SparseCategoricalCrossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "history_1 = model_1.fit(dataset_train,\n",
    "                        epochs=5,\n",
    "                        validation_data=dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history_1)\n",
    "# upload_plot('model_1_plot_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(30,), dtype=\"int32\")\n",
    "x = embedding(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(64, activation=\"tanh\"))(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_Bidirectional\")\n",
    "\n",
    "model_2.compile(loss=\"SparseCategoricalCrossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "history_2 = model_2.fit(dataset_train,\n",
    "                        epochs=5,\n",
    "                        validation_data=dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history_2)\n",
    "# upload_plot('model_2_plot_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Conv1D + Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(30,), dtype=\"int32\")\n",
    "x = embedding(inputs)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Bidirectional(layers.GRU(64))(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_Conv1D_Bidirectional\")\n",
    "\n",
    "model_3.compile(loss=\"SparseCategoricalCrossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "history_3 = model_3.fit(dataset_train,\n",
    "                        epochs=5,\n",
    "                        validation_data=dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history_3)\n",
    "# upload_plot('model_3_plot_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_layer(inputs, SINGLE_ATTENTION_VECTOR=False):\n",
    "    \"\"\"\n",
    "    Implements an attention mechanism layer for a neural network model in Keras.\n",
    "\n",
    "    This function creates an attention mechanism that can be applied to a sequence input to focus on specific parts of the sequence \n",
    "    during training. It works by computing attention probabilities for each token in the input sequence and then applying these \n",
    "    probabilities to the input sequence to modulate the importance of each token.\n",
    "\n",
    "    Parameters:\n",
    "    - inputs (tensor): A 3D tensor with shape `(batch_size, n_words, shape_embedding_vector)` representing the input sequence.\n",
    "    - SINGLE_ATTENTION_VECTOR (bool, optional): If True, computes a single attention vector (average across the input sequence) \n",
    "    to be applied across all tokens. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "    - A 3D tensor where the attention mechanism has been applied to the input tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    # inputs(batch_size, n_words, shape_embedding_vector)\n",
    "    num_tokens = K.int_shape(inputs)[1]\n",
    "    embed_dim = K.int_shape(inputs)[2]\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Dense(num_tokens, activation='softmax')(a)\n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(embed_dim)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    return Multiply()([inputs, a_probs])\n",
    "\n",
    "\n",
    "inputs = Input(shape=(30, ), dtype='int32')\n",
    "x = embedding(inputs)  \n",
    "x = layers.SpatialDropout1D(0.2)(x)\n",
    "attention_mul = attention_layer(x)\n",
    "lstm_out = LSTM(64, activation=\"tanh\", dropout=0.3, recurrent_dropout=0.3)(attention_mul)\n",
    "output = Dense(10, activation='softmax')(lstm_out)\n",
    "model_4 = Model(inputs=[inputs], outputs=output)\n",
    "\n",
    "model_4.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history_4 = model_4.fit(dataset_train,\n",
    "                        epochs=12,\n",
    "                        validation_data=dataset_test,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history_4)\n",
    "# upload_plot('model_4_plot_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_is_confused(model, data, labels):\n",
    "    \"\"\"\n",
    "    Analyzes a model's predictions to identify which classes are most frequently misclassified.\n",
    "\n",
    "    This function takes a trained model, data, and true labels, and computes the model's predictions. It identifies the instances \n",
    "    where the model's predictions do not match the true labels and calculates the frequency of misclassifications for each class. \n",
    "    It then returns a DataFrame with the total number of instances, the number of wrong predictions, and the percentage of \n",
    "    misclassifications for each class, sorted by the percentage of misclassifications in descending order.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained model to evaluate.\n",
    "    - data: The input data on which the model makes predictions.\n",
    "    - labels: The true labels corresponding to the input data.\n",
    "\n",
    "    Returns:\n",
    "    - final (pandas.DataFrame): A DataFrame with columns 'Total', 'Wrong', and 'Perc', representing the total number of instances, \n",
    "    number of wrong predictions, and percentage of misclassifications for each class, respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    preds = np.argmax(model.predict(data), axis=1)\n",
    "    \n",
    "    wrong_preds_idx = np.where(preds != labels)\n",
    "    wrong_preds_labels = preds[wrong_preds_idx]\n",
    "    df_wrong_total = pd.Series(Counter(wrong_preds_labels))\n",
    "    \n",
    "    df_total = labels.value_counts()\n",
    "    final = pd.concat([df_total, df_wrong_total], axis=1)\n",
    "    final.columns = ['Total', 'Wrong']\n",
    "    final['Perc'] = final['Wrong'] / final['Total'] * 100\n",
    "    final = final.sort_values(by='Perc', ascending=False)\n",
    "    return final\n",
    "\n",
    "how_is_confused(model_1, test_sentences_vectorized, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def where_is_confused(model, data, target, labels, preds):\n",
    "    \"\"\"\n",
    "    Identifies the distribution of predicted classes for a specific true class, highlighting where a model may be confused.\n",
    "\n",
    "    This function calculates where a trained model tends to misclassify instances of a specific true class. It filters the instances\n",
    "    where the true class matches the specified target class, then analyzes the predictions for these instances to see how they\n",
    "    are distributed across different predicted classes. This helps in understanding the model's confusion regarding the target\n",
    "    class.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained model used for prediction. (Note: The parameter 'model' is not used in the function and can be removed.)\n",
    "    - data: The input data on which predictions were made.\n",
    "    - target: The specific true class for which we want to analyze the predictions.\n",
    "    - labels: The true labels for the input data.\n",
    "    - preds: The predicted labels for the input data.\n",
    "\n",
    "    Returns:\n",
    "    - A pandas Series containing the count of predictions for each class where the true label is the specified target class.\n",
    "    \"\"\"\n",
    "\n",
    "    true_target_preds = np.where(target == labels)\n",
    "    return pd.Series(Counter(preds[true_target_preds]))\n",
    "\n",
    "def create_confusion(model, data, labels):\n",
    "    \"\"\"\n",
    "    Constructs a detailed confusion matrix DataFrame showing misclassification counts for each class pair.\n",
    "\n",
    "    This function predicts class labels for the given data using the provided model, and then analyzes where the model is \n",
    "    confused by comparing the predictions with the true labels. It constructs a confusion matrix where each cell (i, j) \n",
    "    indicates how many times the model predicted class j for instances that are actually of class i. This detailed confusion \n",
    "    matrix helps in understanding the model's performance across different classes.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained model to be evaluated.\n",
    "    - data: The dataset (features) on which predictions are to be made.\n",
    "    - labels: The true labels of the data.\n",
    "\n",
    "    Returns:\n",
    "    - df_confusion (pandas.DataFrame): A DataFrame representing the detailed confusion matrix. Rows represent the true classes, \n",
    "    and columns represent the predicted classes.\n",
    "    \"\"\"\n",
    "\n",
    "    preds = np.argmax(model.predict(data), axis=1)\n",
    "    series_dict = {i: where_is_confused(model, data, i, labels, preds) for i in range(10)}\n",
    "    df_confusion = pd.DataFrame(series_dict)\n",
    "    df_confusion.fillna(0, inplace=True)\n",
    "    df_confusion.index = id2label\n",
    "    df_confusion.columns = id2label\n",
    "    return df_confusion\n",
    "\n",
    "df_confusion = create_confusion(model_4, test_sentences_vectorized, test_labels)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
