{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Marketing Classification Task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Information*\n",
    "\n",
    "The data is related to direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required to assess if the product (bank term deposit) would be subscribed ('yes') or not ('no').\n",
    "\n",
    "*Classification Goal*\n",
    "\n",
    "The goal is to predict if the client will subscribe (yes/no) to a term deposit (variable y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import squarify \n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score, confusion_matrix, precision_score\n",
    "\n",
    "\n",
    "from aws.aws_funcs import upload_to_s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_local_plots = 'path/to/file'\n",
    "def upload_to_aws_png(file_name):\n",
    "    upload_to_s3(f'{path_to_local_plots}{file_name}.png', f'path/png/{file_name}.png')\n",
    "\n",
    "def upload_plot(plot_name):\n",
    "    plt.savefig(f'{path_to_local_plots}{plot_name}.png', dpi=300)\n",
    "    upload_to_aws_png(plot_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_local_csv = 'path/to/file'\n",
    "def upload_to_aws_csv(file_name):\n",
    "    upload_to_s3(f'{path_to_local_csv}{file_name}.csv', f'path/csv/{file_name}.csv')\n",
    "\n",
    "def upload_csv(df, csv_name, index=False):\n",
    "    df.to_csv(f'{path_to_local_csv}{csv_name}.csv', index=index)\n",
    "    upload_to_aws_csv(csv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_categorical(df, column, target=0):\n",
    "    '''\n",
    "    Visualizes the distribution of a categorical variable and its relationship with a binary target variable in a DataFrame.\n",
    "\n",
    "    This function creates a two-part visualization: a treemap and a bar chart. The treemap shows the frequency of each category\n",
    "    in the specified column, providing a visual representation of the size of each category. The bar chart displays the count\n",
    "    of observations for each category, split by the values of a binary target variable ('y'), allowing for an examination of\n",
    "    the relationship between the categorical variable and the target.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The DataFrame containing the data to be visualized.\n",
    "    - column (str): The name of the categorical column to visualize.\n",
    "    - target (int, optional): The binary target variable to compare against. Defaults to 0, assuming 'y' is the target column.\n",
    "\n",
    "    The function does not return any value but displays two plots:\n",
    "    1. A treemap visualization of the categorical variable's frequency.\n",
    "    2. A bar chart showing the count of observations for each category, colored by the binary target variable's value.\n",
    "    '''\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(17,14), dpi=300)\n",
    "    category_sizes = df[column].value_counts().reset_index()\n",
    "    category_sizes.columns = [column, 'counts']\n",
    "\n",
    "    colors = plt.cm.tab20c.colors\n",
    "    squarify.plot(sizes=category_sizes['counts'], label=category_sizes[column], alpha=0.6, color=colors, ax=ax[0])\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title(f'Treemap of {column.capitalize()}s', pad=20)\n",
    "    ax[0].set_xlabel('Category', labelpad=20)\n",
    "    ax[0].set_ylabel('Frequency', labelpad=20);\n",
    "    ax[0].tick_params(axis='x', rotation=45);\n",
    "\n",
    "    temp_df = df.groupby([column, 'y']).size().unstack(fill_value=0)\n",
    "    colormap = plt.cm.coolwarm\n",
    "    colors = [colormap(i) for i in np.linspace(0.1, 0.85, temp_df.shape[1])]\n",
    "    temp_df.plot(kind='bar', stacked=False, ax=ax[1], color=colors)\n",
    "    ax[1].tick_params(axis='x', rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_numerical(df, col, q_min, q_max, upload=1, engineered=0):\n",
    "    \"\"\"\n",
    "    Generates and visualizes statistical summaries for a numerical column in a DataFrame.\n",
    "\n",
    "    This function creates a 2x2 grid of plots for a specified numerical column: histogram with KDE, Q-Q plot, boxplot,\n",
    "    and a quantile line plot for detecting outliers. It allows for an extensive examination of the distribution,\n",
    "    normality, and potential outliers within the data.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The DataFrame containing the data.\n",
    "    - col (str): The numerical column to analyze.\n",
    "    - q_min (float): The minimum quantile to start the range for the outlier plot.\n",
    "    - q_max (float): The maximum quantile to end the range for the outlier plot.\n",
    "    - upload (int, optional): Flag to upload the plot. Defaults to 1 (true).\n",
    "    - engineered (int, optional): Flag indicating if the column is engineered. Defaults to 0 (false).\n",
    "\n",
    "    No return value; the function plots and optionally uploads the visualizations.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 2, figsize=(15, 8))\n",
    "\n",
    "    sns.histplot(data=df, x=col, kde=True, ax=ax[0, 0])\n",
    "\n",
    "    stats.probplot(x=df[col], dist=stats.norm, plot=ax[0, 1])\n",
    "\n",
    "    sns.boxplot(data=df, x=col, ax=ax[1, 0])\n",
    "\n",
    "    pts = df[col].quantile(q=np.arange(q_min, q_max, 0.01))\n",
    "    sns.lineplot(x=pts.index, y=pts, ax=ax[1, 1])\n",
    "\n",
    "    titles_name = [[\"Histogram\", \"QQ plot\"], [\"Boxplot\", \"Outlier\"]]\n",
    "\n",
    "    for i, j in product(range(2), repeat=2):\n",
    "        ax[i, j].set_title(titles_name[i][j].capitalize(), pad=20)\n",
    "\n",
    "    plt.suptitle(f\"Distribution of: {col.capitalize()}\", fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    if upload:\n",
    "        if engineered:\n",
    "            upload_plot(f'distribution_{col}_engineered')\n",
    "        else:\n",
    "            upload_plot(f'distribution_{col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_to_target(df, cat, target='y'):\n",
    "    \"\"\"\n",
    "    Calculates the Chi-squared test statistic and p-value for the relationship between a categorical variable and a target variable.\n",
    "\n",
    "    This function applies a Chi-squared test of independence to examine if there is a significant relationship between the categorical\n",
    "    variable and the target variable in the provided DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The DataFrame containing the data.\n",
    "    - cat (str): Column name of the categorical variable.\n",
    "    - target (str, optional): Column name of the target variable. Defaults to 'y'.\n",
    "\n",
    "    Returns:\n",
    "    - chi2 (float): The Chi-squared test statistic.\n",
    "    - p_value (float): The p-value of the test.\n",
    "    - dof (int): Degrees of freedom of the Chi-squared test.\n",
    "    - expected (numpy.ndarray): The expected frequencies, based on the marginal sums of the table.\n",
    "    \"\"\"\n",
    "    \n",
    "    temp = pd.crosstab(df[cat], df[target])\n",
    "    chi2, p_value, dof, expected = chi2_contingency(temp)\n",
    "    return chi2, p_value, dof, expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(features, labels, models, n_folds=5):\n",
    "    \"\"\"\n",
    "    Trains multiple models and evaluates their performance using cross-validation.\n",
    "\n",
    "    This function iterates over a dictionary of models, trains each model using stratified k-fold cross-validation, and \n",
    "    calculates the average accuracy, recall, f1 score, and precision for each model. The performance metrics are then \n",
    "    aggregated into a DataFrame for comparison.\n",
    "\n",
    "    Parameters:\n",
    "    - features (pandas.DataFrame): The feature variables.\n",
    "    - labels (pandas.Series): The target variable.\n",
    "    - models (dict): A dictionary of model name and model instance pairs.\n",
    "\n",
    "    Returns:\n",
    "    - results_df (pandas.DataFrame): A DataFrame containing the average accuracy, recall, f1 score, and precision for each model.\n",
    "    - models (dict): The same dictionary of models that was passed in, after they have been fit to the data.\n",
    "    \"\"\"\n",
    "\n",
    "    results = {\n",
    "        'accuracy': [],\n",
    "        'recall': [],\n",
    "        'f1 score': [],\n",
    "        'precision': []\n",
    "    }\n",
    "\n",
    "    s_fold = StratifiedKFold(\n",
    "    n_splits=n_folds,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "    for name, model in models.items():\n",
    "        fold_accuracy, fold_recall, fold_f1_score, fold_precision = [], [], [], []\n",
    "\n",
    "        for train_idx, val_idx in s_fold.split(features, labels):\n",
    "            X_train, X_val = features.iloc[train_idx], features.iloc[val_idx]\n",
    "            y_train, y_val = labels.iloc[train_idx], labels.iloc[val_idx]\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            preds = model.predict(X_val)\n",
    "            fold_accuracy.append(accuracy_score(y_val, preds))\n",
    "            fold_recall.append(recall_score(y_val, preds))\n",
    "            fold_f1_score.append(f1_score(y_val, preds))\n",
    "            fold_precision.append(precision_score(y_val, preds))\n",
    "\n",
    "        avg_accuracy = np.mean(fold_accuracy)\n",
    "        avg_recall = np.mean(fold_recall)\n",
    "        avg_f1_score = np.mean(fold_f1_score)\n",
    "        avg_precision = np.mean(fold_precision)\n",
    "        \n",
    "        results['accuracy'].append(avg_accuracy)\n",
    "        results['recall'].append(avg_recall)\n",
    "        results['f1 score'].append(avg_f1_score)\n",
    "        results['precision'].append(avg_precision)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.index = models.keys()\n",
    "    return results_df, models\n",
    "\n",
    "\n",
    "def test_models(features, labels, models):\n",
    "    \"\"\"\n",
    "    Tests the performance of multiple trained models on a dataset.\n",
    "\n",
    "    Evaluates each model's accuracy, recall, f1 score, and precision on the provided features and labels. The function iterates \n",
    "    through a dictionary of trained model instances, uses them to predict labels for the given features, and calculates the \n",
    "    performance metrics for each model. These metrics are compiled into a DataFrame for easy comparison.\n",
    "\n",
    "    Parameters:\n",
    "    - features (pandas.DataFrame): The feature variables for testing.\n",
    "    - labels (pandas.Series): The true labels for performance evaluation.\n",
    "    - models (dict): A dictionary where keys are model names and values are trained model instances.\n",
    "\n",
    "    Returns:\n",
    "    - results_df (pandas.DataFrame): A DataFrame with each model's accuracy, recall, f1 score, and precision.\n",
    "    \"\"\"\n",
    "\n",
    "    results = {\n",
    "        'accuracy': [],\n",
    "        'recall': [],\n",
    "        'f1 score': [],\n",
    "        'precision': []\n",
    "    }\n",
    "\n",
    "    for name, model in models.items():\n",
    "        preds = model.predict(features)\n",
    "        results['accuracy'].append(accuracy_score(labels, preds))\n",
    "        results['recall'].append(recall_score(labels, preds))\n",
    "        results['f1 score'].append(f1_score(labels, preds))\n",
    "        results['precision'].append(precision_score(labels, preds))\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.index = models.keys()\n",
    "    return results_df \n",
    "\n",
    "\n",
    "def confusion_matrix_plot(features, labels, models, upload=0):\n",
    "    \"\"\"\n",
    "    Plots confusion matrices for given models on a dataset and optionally uploads the plots.\n",
    "\n",
    "    This function iterates over a dictionary of models, predicts labels for a given set of features using each model, and then \n",
    "    plots the confusion matrix for the predicted versus actual labels. It can also upload the generated plots if required.\n",
    "\n",
    "    Parameters:\n",
    "    - features (pandas.DataFrame): The feature variables for the dataset.\n",
    "    - labels (pandas.Series): The true labels for the dataset.\n",
    "    - models (dict): A dictionary of model name and model instance pairs.\n",
    "    - upload (int, optional): Flag to determine whether to upload the plots. If 1, plots are uploaded. Defaults to 0.\n",
    "    \"\"\"\n",
    "\n",
    "    for name, model in models.items():\n",
    "        preds = model.predict(features)\n",
    "        confusion_matrix_model = confusion_matrix(labels, preds)\n",
    "        fig, ax = plt.subplots(figsize=(8, 4), dpi=150)\n",
    "        sns.heatmap(confusion_matrix_model, annot=True, fmt='d', cmap='coolwarm_r', ax=ax, alpha=0.5)\n",
    "        ax.set_xlabel('Predictions', labelpad=20)\n",
    "        ax.set_ylabel('True', labelpad=20)\n",
    "        ax.set_title(name, pad=20)\n",
    "        if upload:\n",
    "            upload_plot(f'{upload}_{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data and the First Impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = pathlib.Path('data/bank_data.csv')\n",
    "df = pd.read_csv(path_data.__str__())\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(df.head(20), 'raw_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately get rid of the column *Unnamed 0*, since it duplicates the index column and doesn't have any useful information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[column for column in df.columns if column != 'Unnamed: 0']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(df.head(20), 'without_null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nulls = pd.DataFrame(df.isnull().sum()).reset_index()\n",
    "df_nulls.columns = ['Column', 'Number of Nulls']\n",
    "\n",
    "df_nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are no *NULL* values in our df and we want to separate numerical and categorical types of columns to make there analysis more productive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(df_nulls, 'is_there_null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df = df.select_dtypes(include='number')\n",
    "numerical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(numerical_df.head(20), 'numerical_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(numerical_df.describe(), 'numerical_describe', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_df = df[[column for column in df.columns if column not in numerical_df.columns]]\n",
    "categorical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(categorical_df.head(20), 'categorical_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(categorical_df.describe(), 'categorical_describe', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numerical_df.columns:\n",
    "    summary_numerical(numerical_df, column, 0.85, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile /Users/konstantinsokolovskiy/Desktop/My_Big_Project/final/projects/projects/project_3/data/code_snippets/correlation_matrix.txt\n",
    "fig, ax = plt.subplots(figsize = (5, 5), dpi=200)\n",
    "\n",
    "sns.heatmap(\n",
    "    data=numerical_df.corr(),\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    linecolor=\"white\",\n",
    "    linewidth=0.5,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    ax=ax\n",
    ")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Correlations'); \n",
    "upload_plot('correlation_matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile /Users/konstantinsokolovskiy/Desktop/My_Big_Project/final/projects/projects/project_3/data/code_snippets/multicollinearity.txt\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = numerical_df.columns\n",
    "\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(numerical_df.values, i) \n",
    "                   for i in range(numerical_df.shape[1])]\n",
    "\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(vif_data, 'vif_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_categorical_features = partial(count_categorical, df=categorical_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_categorical_features(column='y', target=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_categorical_features(column='job')\n",
    "upload_plot('distribution_job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_job, p_job, _, _ = cat_to_target(categorical_df, 'job')\n",
    "p_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Marital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_categorical_features(column='marital')\n",
    "upload_plot('distribution_marital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_marital, p_marital, _, _ = cat_to_target(categorical_df, 'marital')\n",
    "p_marital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_categorical_features(column='education')\n",
    "upload_plot('distribution_education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_education, p_education, _, _ = cat_to_target(categorical_df, 'education')\n",
    "p_education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_categorical_features(column='default')\n",
    "upload_plot('distribution_default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_default, p_default, _, _ = cat_to_target(categorical_df, 'default')\n",
    "p_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_categorical_features(column='housing')\n",
    "upload_plot('distribution_housing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_housing, p_housing, _, _ = cat_to_target(categorical_df, 'housing')\n",
    "p_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_categorical_features(column='loan')\n",
    "upload_plot('distribution_loan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_loan, p_loan, _, _ = cat_to_target(categorical_df, 'loan')\n",
    "p_loan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_categorical_features(column='contact')\n",
    "upload_plot('distribution_contact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_contact, p_contact, _, _ = cat_to_target(categorical_df, 'contact')\n",
    "p_contact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_categorical_features(column='month')\n",
    "upload_plot('distribution_month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_month, p_month, _, _ = cat_to_target(categorical_df, 'month')\n",
    "p_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Poutcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_categorical_features(column='poutcome')\n",
    "upload_plot('distribution_poutcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_poutcome, p_poutcome, _, _ = cat_to_target(categorical_df, 'poutcome')\n",
    "p_poutcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_result = pd.DataFrame({\n",
    "    'category': ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact','month', 'poutcome'],\n",
    "    'p_value': [p_job, p_marital, p_education, p_default, p_housing, p_loan, p_contact, p_month, p_poutcome], \n",
    "    })\n",
    "p_result['is_it'] = p_result['p_value'].apply(lambda x: 1 if x < 0.05 else 0)\n",
    "p_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(p_result, 'chi2_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conducting the Chi2 test we see that only one categorical feature, *default*, doesn't have the influence on result, so we can get rid of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model. No Feature Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_base = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(df_for_base.drop('y', axis=1), \n",
    "                                                    df_for_base['y'], \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df_for_base['y'])\n",
    "\n",
    "\n",
    "X_train_base.reset_index(drop=True, inplace=True)\n",
    "X_test_base.reset_index(drop=True, inplace=True)\n",
    "\n",
    "y_train_base = y_train_base.map({'no': 0, 'yes': 1}).reset_index(drop=True)\n",
    "y_test_base = y_test_base.map({'no': 0, 'yes': 1}).reset_index(drop=True)\n",
    "\n",
    "X_train_base_final = pd.get_dummies(\n",
    "        X_train_base,\n",
    "        columns=categorical_df.columns[:-1],\n",
    "        drop_first=True)\n",
    "\n",
    "X_test_base_final = pd.get_dummies(\n",
    "        X_test_base,\n",
    "        columns=categorical_df.columns[:-1],\n",
    "        drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = {\n",
    "    'Logistic Regregression': LogisticRegression(max_iter=5000,),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'SVC': SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "s_fold = StratifiedKFold(\n",
    "    n_splits=n_folds,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results_train, trained_base_models = train_models(X_train_base_final, y_train_base, base_models)\n",
    "base_results_test = test_models(X_test_base_final, y_test_base, trained_base_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(base_results_train, csv_name='base_results_train', index=True)\n",
    "upload_csv(base_results_test, csv_name='base_results_test', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12), dpi=200)\n",
    "plot_importance(trained_base_models['XGBoost'], ax=ax);\n",
    "upload_plot('base_feature_importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_plot(X_test_base_final, y_test_base, trained_base_models, upload='base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = trained_base_models['XGBoost'].get_booster().get_score(importance_type='weight')\n",
    "\n",
    "sorted_importance = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7), dpi=200)\n",
    "x = np.arange(len(sorted_importance))\n",
    "y = [elem[1] for elem in sorted_importance]\n",
    "plt.plot(x, y, marker='o');\n",
    "plt.xlabel('Feature Number', labelpad=20)\n",
    "plt.ylabel('Feature Importance', labelpad=20)\n",
    "plt.grid(True)\n",
    "upload_plot('base_feature_importance_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 20\n",
    "top_features = [pair[0] for pair in sorted_importance][:num_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models_top_features = {\n",
    "    'Logistic Regregression': LogisticRegression(max_iter=5000,),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results_top_features_train, trained_base_models_top_features = train_models(\n",
    "    X_train_base_final[top_features], \n",
    "    y_train_base, \n",
    "    base_models_top_features\n",
    "    )\n",
    "base_results_top_features_test = test_models(X_test_base_final[top_features], y_test_base, trained_base_models_top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results_top_features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results_top_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(base_results_top_features_train, 'base_results_top_features_train', index=True)\n",
    "upload_csv(base_results_top_features_test, 'base_results_top_features_test', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models_grid = {\n",
    "    'Logistic Regregression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'Logistic Regregression': {\n",
    "        'solver': ['liblinear', 'lbfgs'],\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l2'],\n",
    "        'max_iter': [5_000]\n",
    "    },\n",
    "\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [10, 50, 100, 500],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 4, 6]\n",
    "    },\n",
    "\n",
    "    'XGBoost': {\n",
    "        'max_depth': [5, 6],\n",
    "        'learning_rate': [0.001, 0.01],\n",
    "        'n_estimators': [300, 1000, 2000],\n",
    "        'subsample': [0.7, 0.85, 1]\n",
    "        }\n",
    "}\n",
    "best_params = {}\n",
    "for name, model in base_models_grid.items():\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid[name], scoring='precision', cv=3)\n",
    "    grid_search.fit(X_train_base_final[top_features], y_train_base)\n",
    "    best_params[name] = grid_search.best_params_\n",
    "    print(f'For model {name} the best params: {grid_search.best_params_} \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_best_params = pd.DataFrame(best_params).fillna('-')\n",
    "upload_csv(base_best_params, 'base_best_params', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models_best = {\n",
    "    'Logistic Regregression': LogisticRegression(**best_params['Logistic Regregression']),\n",
    "    'Random Forest': RandomForestClassifier(**best_params['Random Forest']),\n",
    "    'XGBoost': XGBClassifier(**best_params['XGBoost']),\n",
    "}\n",
    "\n",
    "base_models_best_results_train, trained_base_models_best = train_models(\n",
    "    X_train_base_final[top_features], \n",
    "    y_train_base, \n",
    "    base_models_best\n",
    "    )\n",
    "\n",
    "base_models_best_results_test = test_models(X_test_base_final[top_features], y_test_base, base_models_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models_best_results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models_best_results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(base_models_best_results_train, 'base_models_best_results_train', index=True)\n",
    "upload_csv(base_models_best_results_test, 'base_models_best_results_test', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df_engineered = numerical_df.copy()\n",
    "numerical_df_engineered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineered = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_numerical(df_engineered, 'age', 0.55, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineered['age'] = np.log1p(df_engineered['age'])\n",
    "summary_numerical(df_engineered, 'age', 0.55, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_numerical(df_engineered, 'balance', 0.55, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineered = df_engineered[df_engineered['balance'] < 30_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile /Users/konstantinsokolovskiy/Desktop/My_Big_Project/final/projects/projects/project_3/data/code_snippets/balance_engineered.txt\n",
    "min_balance = abs(df_engineered['balance'].min())\n",
    "df_engineered = df_engineered[df_engineered['balance'] != -min_balance]\n",
    "df_engineered['balance'] = df_engineered['balance'] + min_balance + 1\n",
    "df_engineered['balance'] = np.log1p(df_engineered['balance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_numerical(df_engineered, 'balance', 0.95, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_numerical(df_engineered, 'duration', 0.55, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineered[df_engineered['duration'] > 2_000]['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineered = df_engineered[df_engineered['duration'] <= 2_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineered['duration'] = np.log1p(df_engineered['duration'])\n",
    "summary_numerical(df_engineered, 'duration', 0.95, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_numerical(df_engineered, 'campaign', 0.55, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df['campaign'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_campaign(x):\n",
    "    if x == 1:\n",
    "        return '1'\n",
    "    elif x == 2:\n",
    "        return '2'\n",
    "    elif x in [3, 4]:\n",
    "        return '3-4'\n",
    "    elif x >= 5:\n",
    "        return '5+'\n",
    "\n",
    "df_engineered['campaign'] = df_engineered['campaign'].apply(define_campaign)\n",
    "\n",
    "_, p_value, _, _ = cat_to_target(df_engineered, 'campaign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_numerical(df_engineered, 'pdays', 0.55, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineered['pdays'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_pdays(x):\n",
    "    if x == -1:\n",
    "        return 'no'\n",
    "    elif -1 < x <= 200:\n",
    "        return '< 200'\n",
    "    else:\n",
    "        return '>= 200'\n",
    "\n",
    "df_engineered['pdays'] = df_engineered['pdays'].apply(define_pdays)\n",
    "_, p_value, _, _ = cat_to_target(df_engineered, 'pdays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_numerical(df_engineered, 'previous', 0.55, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineered['previous'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_previous(x):\n",
    "    if x == 0:\n",
    "        return '0'\n",
    "    elif x in [1, 2, 3]:\n",
    "        return '1-3'\n",
    "    else:\n",
    "        return '>3'\n",
    "\n",
    "df_engineered['previous'] = df_engineered['previous'].apply(define_previous)\n",
    "\n",
    "_, p_value, _, _ = cat_to_target(df_engineered, 'previous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Train with fixed Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_engineered = df_engineered.copy()\n",
    "X_train_engineered, X_test_engineered, y_train_engineered, y_test_engineered = train_test_split(df_for_engineered.drop('y', axis=1), \n",
    "                                                    df_for_engineered['y'], \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df_for_engineered['y'])\n",
    "\n",
    "X_train_engineered.reset_index(drop=True, inplace=True)\n",
    "X_test_engineered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "y_train_engineered_final = y_train_engineered.map({'no': 0, 'yes': 1}).reset_index(drop=True)\n",
    "y_test_engineered_final = y_test_engineered.map({'no': 0, 'yes': 1}).reset_index(drop=True)\n",
    "\n",
    "columns_cat = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'campaign', 'pdays', 'previous', 'poutcome']\n",
    "\n",
    "X_train_engineered_final = pd.get_dummies(\n",
    "        X_train_engineered,\n",
    "        columns=columns_cat,\n",
    "        drop_first=True)\n",
    "\n",
    "X_test_engineered_final = pd.get_dummies(\n",
    "        X_test_engineered,\n",
    "        columns=columns_cat,\n",
    "        drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_models = {\n",
    "    'Logistic Regregression': LogisticRegression(max_iter=5000,),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBoost': XGBClassifier(**{'n_estimators': 600, 'subsample': 0.85, 'learning_rate': 0.001530897464421364, 'max_depth': 4})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_results_train, trained_engineered_models = train_models(X_train_engineered_final, y_train_engineered_final, engineered_models)\n",
    "engineered_results_test = test_models(X_test_engineered_final, y_test_engineered_final, trained_engineered_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_csv(engineered_results_train, 'engineered_results_train', index=True)\n",
    "upload_csv(engineered_results_test, 'engineered_results_test', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', low=300, high=1500, step=100)\n",
    "    subsample = trial.suggest_float('subsample', low=0.75, high=0.9, step=0.05)\n",
    "    learning_rate = trial.suggest_float('learning_rate', low=0.001, high=0.05, log=True)\n",
    "    max_depth = trial.suggest_int('max_depth', low=3, high=7, step=1)\n",
    "\n",
    "    xgb_clf = XGBClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        subsample=subsample,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth\n",
    "    )\n",
    "\n",
    "    return cross_val_score(\n",
    "        estimator=xgb_clf,\n",
    "        X=X_train_engineered_final,\n",
    "        y=y_train_engineered_final,\n",
    "        scoring='precision'\n",
    "        ).mean()\n",
    "\n",
    "study = optuna.create_study(\n",
    "    sampler=TPESampler(),\n",
    "    direction='maximize'\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---Bayesian Optimization---\")\n",
    "print('Number of iterations: 100')\n",
    "print(f\"Best trial index: {study.best_trial.number}\")\n",
    "print(f\"Best score: {study.best_trial.value}\")\n",
    "print(f\"Best hyperparameters: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        subsample=0.9,\n",
    "        learning_rate=0.0024,\n",
    "        max_depth=6\n",
    "    )\n",
    "xgb_clf.fit(X_train_engineered_final, y_train_engineered_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(xgb_clf, X_train_engineered_final, y_train_engineered_final, cv=s_fold, scoring='precision')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xgb_clf.predict(X_train_engineered_final)\n",
    "1 - (preds.shape[0] - (preds == y_train_engineered_final.to_numpy()).sum()) / preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xgb_clf.predict(X_test_engineered_final)\n",
    "1 - (preds.shape[0] - (preds == y_test_engineered_final.to_numpy()).sum()) / preds.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
